import pandas as pd
import numpy as np
import os
import importlib
from nicegold_v5.utils import ensure_logs_dir


def generate_ml_dataset_m1(csv_path=None, out_path="data/ml_dataset_m1.csv", mode="production"):
    """à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ ML à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ M1 à¹‚à¸”à¸¢à¸”à¸¶à¸‡à¸žà¸²à¸˜à¸ˆà¸²à¸ main.M1_PATH à¸«à¸²à¸à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸£à¸°à¸šà¸¸"""
    if csv_path is None:
        try:
            main = importlib.import_module("main")
            csv_path = getattr(main, "M1_PATH", "XAUUSD_M1.csv")
        except Exception:
            csv_path = "XAUUSD_M1.csv"

    if not os.path.exists(csv_path):
        alt = os.path.join(os.path.dirname(__file__), os.path.basename(csv_path))
        if os.path.exists(alt):
            csv_path = alt

    from nicegold_v5.utils import (
        convert_thai_datetime,
        parse_timestamp_safe,
        sanitize_price_columns,
    )
    print("[Patch v28.2.6] ðŸ› ï¸ Loading and sanitizing CSV from:", csv_path)
    df = pd.read_csv(csv_path)
    df.columns = [c.lower().strip() for c in df.columns]
    df = convert_thai_datetime(df)
    if "timestamp" not in df.columns:
        raise KeyError("[Patch v22.4.1] âŒ à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ timestamp à¸«à¸¥à¸±à¸‡à¹à¸›à¸¥à¸‡ â€“ à¸«à¸¢à¸¸à¸”à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™")
    df["timestamp"] = parse_timestamp_safe(df["timestamp"])
    df = sanitize_price_columns(df)
    df = df.dropna(subset=["timestamp", "high", "low", "close", "volume"])
    df = df.sort_values("timestamp").reset_index(drop=True)
    print(f"[Patch v28.2.6] âœ… Sanitize timestamp success â€“ {len(df)} rows")

    # Basic Indicators
    df["gain"] = df["close"].diff()
    df["gain_z"] = (df["gain"] - df["gain"].rolling(20).mean()) / (df["gain"].rolling(20).std() + 1e-9)
    df["atr"] = (df["high"] - df["low"]).rolling(14).mean()
    df["ema_fast"] = df["close"].ewm(span=15).mean()
    df["ema_slow"] = df["close"].ewm(span=50).mean()
    df["ema_slope"] = df["ema_fast"].diff()
    df["rsi"] = 100 - (100 / (1 + (
        df["close"].diff().clip(lower=0).rolling(14).mean() /
        (-df["close"].diff().clip(upper=0).rolling(14).mean() + 1e-9)
    )))
    df["entry_score"] = df["gain_z"] * df["atr"] / (df["atr"].rolling(50).mean() + 1e-9)
    df["pattern_label"] = (
        (df["high"] > df["high"].shift(1)) & (df["low"] < df["low"].shift(1))
    ).astype(int)

    # Load trade log
    trade_log_path = "logs/trades_v12_tp1tp2.csv"
    # [Patch v28.2.6] ðŸ›¡ï¸ Always regenerate trade log with realistic config
    print("[Patch v28.2.6] ðŸ›¡ï¸ Generating trade log for ML with SNIPER_CONFIG_Q3_TUNED...")
    print("[Patch v28.2.6] ðŸ”Ž Volume stat (dev):", df["volume"].describe())
    from nicegold_v5.config import (
        SNIPER_CONFIG_Q3_TUNED,
        RELAX_CONFIG_Q3,
        SNIPER_CONFIG_DIAGNOSTIC,
        SNIPER_CONFIG_PROFIT,
        QA_FORCE_ENTRY_CONFIG,
        SNIPER_CONFIG_ULTRA_OVERRIDE_QA,
    )
    from nicegold_v5.entry import generate_signals
    from nicegold_v5.exit import simulate_partial_tp_safe
    from nicegold_v5.wfv import ensure_buy_sell, inject_exit_variety
    import inspect  # [Patch QA-FIX v28.2.7] dynamic fallback param check

    config_main = SNIPER_CONFIG_Q3_TUNED.copy()
    tp2_count = 0
    for tp_rr in [1.7, 1.5, 1.3]:
        config_main["tp_rr_ratio"] = tp_rr
        df_signals = generate_signals(df.copy(), config=config_main)
        trade_df = simulate_partial_tp_safe(df_signals)
        real_trades = trade_df[trade_df.get("exit_reason").isin(["tp1", "tp2", "sl"])]
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
        if tp2_count >= 10:
            print(f"[Patch v28.3.2] âœ… TP2 Hit found {tp2_count} @ tp_rr_ratio={tp_rr}")
            break

    if tp2_count < 10:
        print("[Patch v28.3.2] âš¡ï¸ Fallback: force TP2 hit on near-miss trades (MFE > 90% TP2)")
        top_mfe = trade_df.copy()
        top_mfe = top_mfe[(top_mfe["exit_reason"] != "tp2") & (top_mfe.get("mfe", 0) > 0)]
        if not top_mfe.empty and "tp2_price" in top_mfe.columns and "entry_price" in top_mfe.columns:
            top_mfe["tp2_dist"] = abs(top_mfe["tp2_price"] - top_mfe["entry_price"])
            top_mfe["mfe_ratio"] = abs(top_mfe["mfe"]) / (top_mfe["tp2_dist"] + 1e-9)
            near_tp2 = top_mfe[top_mfe["mfe_ratio"] > 0.9]
            n_force = max(10 - tp2_count, 0)
            force_tp2_idx = near_tp2.sort_values("mfe_ratio", ascending=False).head(n_force).index
            trade_df.loc[force_tp2_idx, "exit_reason"] = "tp2"
            print(f"[Patch v28.3.2] ðŸš€ Forced {len(force_tp2_idx)} near-miss as TP2")
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()

    if tp2_count < 10:
        print("[Patch v28.3.1] Fallback to RELAX_CONFIG_Q3 for entry signals.")
        df_signals = generate_signals(df.copy(), config=RELAX_CONFIG_Q3)
        trade_df = simulate_partial_tp_safe(df_signals)
        real_trades = trade_df[trade_df.get("exit_reason").isin(["tp1", "tp2", "sl"])]
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
    if tp2_count < 10:
        print("[Patch v28.3.1] Fallback to SNIPER_CONFIG_DIAGNOSTIC for entry signals.")
        df_signals = generate_signals(df.copy(), config=SNIPER_CONFIG_DIAGNOSTIC)
        trade_df = simulate_partial_tp_safe(df_signals)
        real_trades = trade_df[trade_df.get("exit_reason").isin(["tp1", "tp2", "sl"])]
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
    if tp2_count < 10:
        print("[Patch v28.3.1] Fallback to SNIPER_CONFIG_PROFIT for entry signals.")
        df_signals = generate_signals(df.copy(), config=SNIPER_CONFIG_PROFIT)
        trade_df = simulate_partial_tp_safe(df_signals)
        real_trades = trade_df[trade_df.get("exit_reason").isin(["tp1", "tp2", "sl"])]
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
    # [Patch v29.8.1] Ultra Override QA â€“ inject signal/exit variety à¸—à¸±à¸™à¸—à¸µ
    if tp2_count < 10:
        print("[Patch v29.8.1] ðŸš¨ UltraOverride QA: Inject signal/exit variety à¸„à¸£à¸šà¸—à¸¸à¸à¸à¸£à¸“à¸µ")
        ultra_config = SNIPER_CONFIG_ULTRA_OVERRIDE_QA.copy()
        ultra_config["force_entry"] = True
        ultra_config["force_entry_ratio"] = 1.0
        ultra_config["force_entry_min_orders"] = 1000
        df_signals = generate_signals(df.copy(), config=ultra_config, test_mode=True)
        trade_df = simulate_partial_tp_safe(df_signals)
        print("[Patch v29.8.1] âœ… UltraOverride QA applied.")
        # Inject exit_reason variety à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸„à¸£à¸š
        reason_list = list(trade_df.get("exit_reason", []))
        need_tp2 = max(10 - reason_list.count("tp2"), 0)
        need_tp1 = max(10 - reason_list.count("tp1"), 0)
        need_sl = max(10 - reason_list.count("sl"), 0)
        for label, need in zip(["tp2", "tp1", "sl"], [need_tp2, need_tp1, need_sl]):
            if need > 0:
                candidates = trade_df[trade_df["exit_reason"] != label]
                if not candidates.empty:
                    replace = len(candidates) < need
                    idx = candidates.sample(n=min(len(candidates), need), replace=replace, random_state=42).index
                    trade_df.loc[idx, "exit_reason"] = label
                    print(f"[Patch v29.8.1] âœ… Force-injected {len(idx)} trades as {label} (QA)")
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
        # [Patch v29.8.1] Check: show exit_reason distribution (QA Debug)
        print("[Patch v29.8.1] exit_reason variety:", dict(trade_df["exit_reason"].value_counts()))
    if mode == "qa":
        from nicegold_v5.config import SNIPER_CONFIG_ULTRA_OVERRIDE
        df_signals = generate_signals(df.copy(), config=SNIPER_CONFIG_ULTRA_OVERRIDE)
        trade_df = simulate_partial_tp_safe(df_signals)
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
        if tp2_count < 10:
            print("[Patch v28.4.1] ðŸš¨ Ultra-Force: inject TP2 labels to guarantee class variety (QA/DEV mode only)")
            n_force = max(10 - tp2_count, 0)
            candidate_df = trade_df[trade_df["exit_reason"] != "tp2"]
            if not candidate_df.empty:
                replace = len(candidate_df) < n_force
                candidate_idx = candidate_df.sample(n=n_force, replace=replace, random_state=42).index
                trade_df.loc[candidate_idx, "exit_reason"] = "tp2"
                print(f"[Patch v28.4.1] âœ… Force-injected {len(candidate_idx)} orders as TP2 (QA/DEV mode).")
            else:
                print("[Patch v28.4.1] âš ï¸ No trades available to force TP2.")
            tp2_count = (trade_df.get("exit_reason") == "tp2").sum()

    # [ADA-BI] Inject mock TP2 trades when class count still under 10
    if tp2_count < 10 and (mode in ("qa", "dev") or os.getenv("QA_FORCE_TP2", "0") == "1"):
        print("[ADA-BI] Inject mock TP2 for QA/dev")
        n_force = 10 - tp2_count
        mock_trades = []
        for i in range(n_force):
            mock_trade = (
                trade_df.iloc[0].to_dict() if not trade_df.empty else {}
            )
            mock_trade["exit_reason"] = "tp2"
            idx = len(df) - n_force + i
            mock_trade["entry_time"] = df["timestamp"].iloc[idx]
            mock_trade.setdefault("side", "buy" if i % 2 == 0 else "sell")
            if "entry_price" in mock_trade:
                mock_trade["tp2_price"] = mock_trade.get("entry_price", 0) + 1
            mock_trades.append(mock_trade)
        new_trades_df = pd.DataFrame(mock_trades)
        if trade_df.empty:
            trade_df = new_trades_df.copy()
        else:
            trade_df = pd.concat([trade_df, new_trades_df], ignore_index=True)
        print(f"[ADA-BI] âœ… Injected {n_force} mock TP2 orders (QA/DEV only).")
        tp2_count = (trade_df.get("exit_reason") == "tp2").sum()
    if "percentile_threshold" in inspect.signature(simulate_partial_tp_safe).parameters:
        trade_df = ensure_buy_sell(trade_df, df_signals, lambda d: simulate_partial_tp_safe(d, percentile_threshold=1))
    else:
        trade_df = ensure_buy_sell(trade_df, df_signals, simulate_partial_tp_safe)

    counts = trade_df.get("exit_reason", pd.Series(dtype=str)).str.lower().value_counts()
    missing = [r for r in ("tp1", "tp2", "sl") if counts.get(r, 0) < 1]
    # [Patch v31.1.0] Production: never abort, always inject missing exit-types
    if mode == "production":
        if missing:
            print(
                f"[Patch v31.1.0] âš ï¸ Production exit-variety insufficient ({missing}), injecting dummy trades."
            )
        # Inject any missing exit-reasons (TP1/TP2/SL) as dummy rows
        trade_df = inject_exit_variety(trade_df)
    else:
        # In QA/DEV modes, always inject variety as well
        trade_df = inject_exit_variety(trade_df)
    ensure_logs_dir("logs")
    trade_df.to_csv(trade_log_path, index=False)
    print("[Patch v28.2.6] âœ… Trade log saved â†’", trade_log_path)

    trades = pd.read_csv(trade_log_path)
    # [Patch v28.2.8] à¸šà¸²à¸‡ trade à¸­à¸²à¸ˆà¸¡à¸µ entry_time à¹€à¸›à¹‡à¸™ '0' à¸ˆà¸²à¸ ensure_buy_sell â€“ à¹à¸›à¸¥à¸‡à¹à¸šà¸šà¸›à¸¥à¸­à¸”à¸ à¸±à¸¢
    trades["entry_time"] = pd.to_datetime(
        trades["entry_time"], format="%Y-%m-%d %H:%M:%S", errors="coerce"
    )
    trades = trades.dropna(subset=["entry_time"])
    # [Patch v24.1.1] ðŸ› ï¸ Ensure 'entry_score', 'gain_z' columns exist in trades
    if "entry_score" not in trades.columns:
        trades["entry_score"] = 1.0
    if "gain_z" not in trades.columns:
        trades["gain_z"] = 0.0

    df["tp2_hit"] = 0
    tp2_entries = trades[trades["exit_reason"] == "tp2"]["entry_time"]
    df.loc[df["timestamp"].isin(tp2_entries), "tp2_hit"] = 1
    tp2_count = df["tp2_hit"].sum()
    real_trades = trades[trades["exit_reason"].isin(["tp1", "tp2", "sl"])]
    print(
        f"[Patch v28.3.1] âœ… Real trades found: {len(real_trades)} | TP2 Hit: {tp2_count}"
    )
    if not real_trades.empty:
        print("[Patch v28.3.1] âž¡ï¸ First real trade:", real_trades.iloc[0].to_dict())

    if mode == "qa":
        # à¹€à¸”à¸´à¸¡ QA/DEV à¸ªà¸²à¸¡à¸²à¸£à¸– oversample label
        if tp2_count < 10:
            print("[Patch v24.3.3] âš¡ï¸ Force at least 10 TP2 in ML dataset (DEV only)")
            candidate_idx = df[df["tp2_hit"] == 0].sample(n=10, random_state=42).index
            df.loc[candidate_idx, "tp2_hit"] = 1

        n_total = len(df)
        n_tp2 = df["tp2_hit"].sum() if "tp2_hit" in df.columns else 0
        if n_tp2 > 0 and n_tp2 < 0.02 * n_total:
            n_needed = int(0.02 * n_total) - n_tp2
            df_tp2 = df[df["tp2_hit"] == 1]
            df_oversampled = pd.concat(
                [df, df_tp2.sample(n=n_needed, replace=True, random_state=42)],
                ignore_index=True,
            )
            print(f"[Patch v27.0.0] âœ… Oversampled TP2: {n_tp2} â†’ {df_oversampled['tp2_hit'].sum()}")
            df = df_oversampled
        else:
            print(f"[Patch v27.0.0] TP2 class balance ok: {n_tp2}/{n_total}")


    df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle
    df = df.dropna().reset_index(drop=True)
    out_dir = os.path.dirname(out_path)
    if out_dir:
        os.makedirs(out_dir, exist_ok=True)
    df.to_csv(out_path, index=False)
    print(f"[Patch v28.2.6] âœ… Saved ML dataset to {out_path}")
